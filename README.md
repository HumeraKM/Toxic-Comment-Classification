# Toxic-Comment-Classification
In this project we focus on a version of the toxic comment classification problem that was posted on Kaggle [https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge], an online platform that is known for hosting data science and machine learning competitions. The problem is the following. Given a user-comment, predict if it should be assigned one or more of the following labels: toxic, severely toxic, obscene, insult, threat, identity hate.

We used three learning algorithms that are known to peform well on text classification: SVM, Multinomial Naive Bayes (MNB) and CNN. The project report can be found in main directory.
